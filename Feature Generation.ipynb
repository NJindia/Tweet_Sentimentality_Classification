{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e25f7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\techn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\techn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\techn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\techn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\techn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests, zipfile, io, re, nltk\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from keras import models, layers\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, TweetTokenizer, wordpunct_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6badafe",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "371865ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         polarity          id                          date     query  \\\n",
       "0               0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1               0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2               0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3               0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4               0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...           ...         ...                           ...       ...   \n",
       "1599995         4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996         4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997         4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998         4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999         4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                              tweet  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin-1', header=None,\n",
    "                         names=['polarity', 'id', 'date', 'query', 'user', 'tweet'])\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d16e3da",
   "metadata": {},
   "source": [
    "### Removing Unnecessary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfc93547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet\n",
       "0        @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1        is upset that he can't update his Facebook by ...\n",
       "2        @Kenichan I dived many times for the ball. Man...\n",
       "3          my whole body feels itchy and like its on fire \n",
       "4        @nationwideclass no, it's not behaving at all....\n",
       "...                                                    ...\n",
       "1599995  Just woke up. Having no school is the best fee...\n",
       "1599996  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999  happy #charitytuesday @theNSPCC @SparksCharity...\n",
       "\n",
       "[1600000 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = raw_df.drop(columns=['id', 'query', 'polarity', 'user', 'date'])\n",
    "# df['datetime'] = raw_df['date'].apply(lambda x: pd.to_datetime(x.replace('PDT ', '')))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fffbb341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Elements of y: [0 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "          ..\n",
       "1599995    1\n",
       "1599996    1\n",
       "1599997    1\n",
       "1599998    1\n",
       "1599999    1\n",
       "Name: polarity, Length: 1600000, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = raw_df['polarity']\n",
    "print(f\"Unique Elements of y: {pd.unique(y)}\")\n",
    "# Change y from [0, 4] to [0, 1]\n",
    "y = y.apply(lambda x: 1 if x==4 else 0)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b36aeb0",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d3c98a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- Awww, that's a bummer.  You shoulda got Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I dived many times for the ball. Managed to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>happy #charitytuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet\n",
       "0          - Awww, that's a bummer.  You shoulda got Da...\n",
       "1        is upset that he can't update his Facebook by ...\n",
       "2         I dived many times for the ball. Managed to s...\n",
       "3          my whole body feels itchy and like its on fire \n",
       "4         no, it's not behaving at all. i'm mad. why am...\n",
       "...                                                    ...\n",
       "1599995  Just woke up. Having no school is the best fee...\n",
       "1599996  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999                          happy #charitytuesday    \n",
       "\n",
       "[1600000 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = df.copy(deep=True)\n",
    "\n",
    "# Remove URLs and User Mentions. All Twitter handles must be within 4 to 15 characters\n",
    "processed_df['tweet'] = processed_df['tweet'].apply(lambda x: re.sub(r\"http\\S+|@\\w{4,15}\", \"\", x))\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5a12bbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentence_tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- Awww, that's a bummer.  You shoulda got Da...</td>\n",
       "      <td>[  - Awww, that's a bummer., You shoulda got D...</td>\n",
       "      <td>[[(-, :), (Awww, NN), (,, ,), (that, IN), (', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>[is upset that he can't update his Facebook by...</td>\n",
       "      <td>[[(is, VBZ), (upset, JJ), (that, IN), (he, PRP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I dived many times for the ball. Managed to s...</td>\n",
       "      <td>[ I dived many times for the ball., Managed to...</td>\n",
       "      <td>[[(I, PRP), (dived, VBD), (many, JJ), (times, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my whole body feels itchy and like its on fire]</td>\n",
       "      <td>[[(my, PRP$), (whole, JJ), (body, NN), (feels,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am...</td>\n",
       "      <td>[ no, it's not behaving at all., i'm mad., why...</td>\n",
       "      <td>[[(no, DT), (,, ,), (it, PRP), (', ''), (s, VB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>[Just woke up., Having no school is the best f...</td>\n",
       "      <td>[[(Just, RB), (woke, VBD), (up, RP), (., .)], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>[TheWDB.com - Very cool to hear old Walt inter...</td>\n",
       "      <td>[[(TheWDB, NNP), (., .), (com, NN), (-, :), (V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>[Are you ready for your MoJo Makeover?, Ask me...</td>\n",
       "      <td>[[(Are, NNP), (you, PRP), (ready, JJ), (for, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>[Happy 38th Birthday to my boo of alll time!!!...</td>\n",
       "      <td>[[(Happy, JJ), (38th, CD), (Birthday, NN), (to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>happy #charitytuesday</td>\n",
       "      <td>[happy #charitytuesday]</td>\n",
       "      <td>[[(happy, JJ), (#charitytuesday, NN)]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  \\\n",
       "0          - Awww, that's a bummer.  You shoulda got Da...   \n",
       "1        is upset that he can't update his Facebook by ...   \n",
       "2         I dived many times for the ball. Managed to s...   \n",
       "3          my whole body feels itchy and like its on fire    \n",
       "4         no, it's not behaving at all. i'm mad. why am...   \n",
       "...                                                    ...   \n",
       "1599995  Just woke up. Having no school is the best fee...   \n",
       "1599996  TheWDB.com - Very cool to hear old Walt interv...   \n",
       "1599997  Are you ready for your MoJo Makeover? Ask me f...   \n",
       "1599998  Happy 38th Birthday to my boo of alll time!!! ...   \n",
       "1599999                          happy #charitytuesday       \n",
       "\n",
       "                                           sentence_tokens  \\\n",
       "0        [  - Awww, that's a bummer., You shoulda got D...   \n",
       "1        [is upset that he can't update his Facebook by...   \n",
       "2        [ I dived many times for the ball., Managed to...   \n",
       "3         [my whole body feels itchy and like its on fire]   \n",
       "4        [ no, it's not behaving at all., i'm mad., why...   \n",
       "...                                                    ...   \n",
       "1599995  [Just woke up., Having no school is the best f...   \n",
       "1599996  [TheWDB.com - Very cool to hear old Walt inter...   \n",
       "1599997  [Are you ready for your MoJo Makeover?, Ask me...   \n",
       "1599998  [Happy 38th Birthday to my boo of alll time!!!...   \n",
       "1599999                            [happy #charitytuesday]   \n",
       "\n",
       "                                                  pos_tags  \n",
       "0        [[(-, :), (Awww, NN), (,, ,), (that, IN), (', ...  \n",
       "1        [[(is, VBZ), (upset, JJ), (that, IN), (he, PRP...  \n",
       "2        [[(I, PRP), (dived, VBD), (many, JJ), (times, ...  \n",
       "3        [[(my, PRP$), (whole, JJ), (body, NN), (feels,...  \n",
       "4        [[(no, DT), (,, ,), (it, PRP), (', ''), (s, VB...  \n",
       "...                                                    ...  \n",
       "1599995  [[(Just, RB), (woke, VBD), (up, RP), (., .)], ...  \n",
       "1599996  [[(TheWDB, NNP), (., .), (com, NN), (-, :), (V...  \n",
       "1599997  [[(Are, NNP), (you, PRP), (ready, JJ), (for, I...  \n",
       "1599998  [[(Happy, JJ), (38th, CD), (Birthday, NN), (to...  \n",
       "1599999             [[(happy, JJ), (#charitytuesday, NN)]]  \n",
       "\n",
       "[1600000 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize Tweets into Sentences and Extract Part-Of-Speech Tags\n",
    "processed_df['sentence_tokens'] = processed_df['tweet'].apply(lambda x: sent_tokenize(x))\n",
    "tokenizer = RegexpTokenizer(r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)|\\w+|[^\\w\\s]+\")\n",
    "processed_df['pos_tags'] = processed_df['sentence_tokens'].apply(lambda x: [nltk.pos_tag(tokenizer.tokenize(sent)) for sent in x])\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8d02fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentence_tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>word_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- Awww, that's a bummer.  You shoulda got Da...</td>\n",
       "      <td>[  - Awww, that's a bummer., You shoulda got D...</td>\n",
       "      <td>[[(-, :), (Awww, NN), (,, ,), (that, IN), (', ...</td>\n",
       "      <td>[-, Awww, ,, that, ', s, a, bummer, ., You, sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>[is upset that he can't update his Facebook by...</td>\n",
       "      <td>[[(is, VBZ), (upset, JJ), (that, IN), (he, PRP...</td>\n",
       "      <td>[is, upset, that, he, can, ', t, update, his, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I dived many times for the ball. Managed to s...</td>\n",
       "      <td>[ I dived many times for the ball., Managed to...</td>\n",
       "      <td>[[(I, PRP), (dived, VBD), (many, JJ), (times, ...</td>\n",
       "      <td>[I, dived, many, times, for, the, ball, ., Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my whole body feels itchy and like its on fire]</td>\n",
       "      <td>[[(my, PRP$), (whole, JJ), (body, NN), (feels,...</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am...</td>\n",
       "      <td>[ no, it's not behaving at all., i'm mad., why...</td>\n",
       "      <td>[[(no, DT), (,, ,), (it, PRP), (', ''), (s, VB...</td>\n",
       "      <td>[no, ,, it, ', s, not, behaving, at, all, ., i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>[Just woke up., Having no school is the best f...</td>\n",
       "      <td>[[(Just, RB), (woke, VBD), (up, RP), (., .)], ...</td>\n",
       "      <td>[Just, woke, up, ., Having, no, school, is, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>[TheWDB.com - Very cool to hear old Walt inter...</td>\n",
       "      <td>[[(TheWDB, NNP), (., .), (com, NN), (-, :), (V...</td>\n",
       "      <td>[TheWDB, ., com, -, Very, cool, to, hear, old,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>[Are you ready for your MoJo Makeover?, Ask me...</td>\n",
       "      <td>[[(Are, NNP), (you, PRP), (ready, JJ), (for, I...</td>\n",
       "      <td>[Are, you, ready, for, your, MoJo, Makeover, ?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>[Happy 38th Birthday to my boo of alll time!!!...</td>\n",
       "      <td>[[(Happy, JJ), (38th, CD), (Birthday, NN), (to...</td>\n",
       "      <td>[Happy, 38th, Birthday, to, my, boo, of, alll,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>happy #charitytuesday</td>\n",
       "      <td>[happy #charitytuesday]</td>\n",
       "      <td>[[(happy, JJ), (#charitytuesday, NN)]]</td>\n",
       "      <td>[happy, #charitytuesday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  \\\n",
       "0          - Awww, that's a bummer.  You shoulda got Da...   \n",
       "1        is upset that he can't update his Facebook by ...   \n",
       "2         I dived many times for the ball. Managed to s...   \n",
       "3          my whole body feels itchy and like its on fire    \n",
       "4         no, it's not behaving at all. i'm mad. why am...   \n",
       "...                                                    ...   \n",
       "1599995  Just woke up. Having no school is the best fee...   \n",
       "1599996  TheWDB.com - Very cool to hear old Walt interv...   \n",
       "1599997  Are you ready for your MoJo Makeover? Ask me f...   \n",
       "1599998  Happy 38th Birthday to my boo of alll time!!! ...   \n",
       "1599999                          happy #charitytuesday       \n",
       "\n",
       "                                           sentence_tokens  \\\n",
       "0        [  - Awww, that's a bummer., You shoulda got D...   \n",
       "1        [is upset that he can't update his Facebook by...   \n",
       "2        [ I dived many times for the ball., Managed to...   \n",
       "3         [my whole body feels itchy and like its on fire]   \n",
       "4        [ no, it's not behaving at all., i'm mad., why...   \n",
       "...                                                    ...   \n",
       "1599995  [Just woke up., Having no school is the best f...   \n",
       "1599996  [TheWDB.com - Very cool to hear old Walt inter...   \n",
       "1599997  [Are you ready for your MoJo Makeover?, Ask me...   \n",
       "1599998  [Happy 38th Birthday to my boo of alll time!!!...   \n",
       "1599999                            [happy #charitytuesday]   \n",
       "\n",
       "                                                  pos_tags  \\\n",
       "0        [[(-, :), (Awww, NN), (,, ,), (that, IN), (', ...   \n",
       "1        [[(is, VBZ), (upset, JJ), (that, IN), (he, PRP...   \n",
       "2        [[(I, PRP), (dived, VBD), (many, JJ), (times, ...   \n",
       "3        [[(my, PRP$), (whole, JJ), (body, NN), (feels,...   \n",
       "4        [[(no, DT), (,, ,), (it, PRP), (', ''), (s, VB...   \n",
       "...                                                    ...   \n",
       "1599995  [[(Just, RB), (woke, VBD), (up, RP), (., .)], ...   \n",
       "1599996  [[(TheWDB, NNP), (., .), (com, NN), (-, :), (V...   \n",
       "1599997  [[(Are, NNP), (you, PRP), (ready, JJ), (for, I...   \n",
       "1599998  [[(Happy, JJ), (38th, CD), (Birthday, NN), (to...   \n",
       "1599999             [[(happy, JJ), (#charitytuesday, NN)]]   \n",
       "\n",
       "                                               word_tokens  \n",
       "0        [-, Awww, ,, that, ', s, a, bummer, ., You, sh...  \n",
       "1        [is, upset, that, he, can, ', t, update, his, ...  \n",
       "2        [I, dived, many, times, for, the, ball, ., Man...  \n",
       "3        [my, whole, body, feels, itchy, and, like, its...  \n",
       "4        [no, ,, it, ', s, not, behaving, at, all, ., i...  \n",
       "...                                                    ...  \n",
       "1599995  [Just, woke, up, ., Having, no, school, is, th...  \n",
       "1599996  [TheWDB, ., com, -, Very, cool, to, hear, old,...  \n",
       "1599997  [Are, you, ready, for, your, MoJo, Makeover, ?...  \n",
       "1599998  [Happy, 38th, Birthday, to, my, boo, of, alll,...  \n",
       "1599999                           [happy, #charitytuesday]  \n",
       "\n",
       "[1600000 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pattern = regex.compile(r\"(.)/\\1{2,}\")\n",
    "# pattern.sub(r\"\\1\\1\\1\", text)\n",
    "# Tokenize Tweets into Words\n",
    "processed_df['word_tokens'] = processed_df['tweet'].apply(lambda x: tokenizer.tokenize(x))\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "faec49a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Words:  ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Generate stop words\n",
    "print(\"Stop Words: \", stopwords.words('english'))\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Remove stop words from tokenized tweets\n",
    "processed_df['word_tokens_no_stop_words'] = processed_df['word_tokens'].apply(lambda x: [w for w in x if not w.lower() in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c023a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming words in Tweet\n",
    "ps = PorterStemmer()\n",
    "processed_df['word_tokens_no_stop_stemmed'] = processed_df['word_tokens_no_stop_words'].apply(lambda x: [ps.stem(w) for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "864b51e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " 'Awww',\n",
       " ',',\n",
       " \"'\",\n",
       " 'bummer',\n",
       " '.',\n",
       " 'shoulda',\n",
       " 'got',\n",
       " 'David',\n",
       " 'Carr',\n",
       " 'Third',\n",
       " 'Day',\n",
       " '.',\n",
       " ';']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df['word_tokens_no_stop_words'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "318f76fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentence_tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>word_tokens_no_stop_words</th>\n",
       "      <th>word_tokens_no_stop_stemmed</th>\n",
       "      <th>word_tokens_no_stop_adjusted_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- Awww, that's a bummer.  You shoulda got Da...</td>\n",
       "      <td>[  - Awww, that's a bummer., You shoulda got D...</td>\n",
       "      <td>[[(-, :), (Awww, NN), (,, ,), (that, IN), (', ...</td>\n",
       "      <td>[-, Awww, ,, that, ', s, a, bummer, ., You, sh...</td>\n",
       "      <td>[-, Awww, ,, ', bummer, ., shoulda, got, David...</td>\n",
       "      <td>[-, awww, ,, ', bummer, ., shoulda, got, david...</td>\n",
       "      <td>[:, NN, ,, IN, '', VB, DT, NN, ., PRP, VBP, VB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>[is upset that he can't update his Facebook by...</td>\n",
       "      <td>[[(is, VBZ), (upset, JJ), (that, IN), (he, PRP...</td>\n",
       "      <td>[is, upset, that, he, can, ', t, update, his, ...</td>\n",
       "      <td>[upset, ', update, Facebook, texting, ..., mig...</td>\n",
       "      <td>[upset, ', updat, facebook, text, ..., might, ...</td>\n",
       "      <td>[VBZ, JJ, IN, PRP, MD, '', VB, VB, PRP$, NNP, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I dived many times for the ball. Managed to s...</td>\n",
       "      <td>[ I dived many times for the ball., Managed to...</td>\n",
       "      <td>[[(I, PRP), (dived, VBD), (many, JJ), (times, ...</td>\n",
       "      <td>[I, dived, many, times, for, the, ball, ., Man...</td>\n",
       "      <td>[dived, many, times, ball, ., Managed, save, 5...</td>\n",
       "      <td>[dive, mani, time, ball, ., manag, save, 50, %...</td>\n",
       "      <td>[PRP, VBD, JJ, NNS, IN, DT, NN, ., VBN, TO, VB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my whole body feels itchy and like its on fire]</td>\n",
       "      <td>[[(my, PRP$), (whole, JJ), (body, NN), (feels,...</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
       "      <td>[whole, bodi, feel, itchi, like, fire]</td>\n",
       "      <td>[PRP$, JJ, NN, NNS, VBP, CC, VBP, PRP$, IN, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am...</td>\n",
       "      <td>[ no, it's not behaving at all., i'm mad., why...</td>\n",
       "      <td>[[(no, DT), (,, ,), (it, PRP), (', ''), (s, VB...</td>\n",
       "      <td>[no, ,, it, ', s, not, behaving, at, all, ., i...</td>\n",
       "      <td>[,, ', behaving, ., ', mad, ., ?, ', see, .]</td>\n",
       "      <td>[,, ', behav, ., ', mad, ., ?, ', see, .]</td>\n",
       "      <td>[DT, ,, PRP, '', VBZ, RB, VBG, IN, DT, ., NN, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>[Just woke up., Having no school is the best f...</td>\n",
       "      <td>[[(Just, RB), (woke, VBD), (up, RP), (., .)], ...</td>\n",
       "      <td>[Just, woke, up, ., Having, no, school, is, th...</td>\n",
       "      <td>[woke, ., school, best, feeling, ever]</td>\n",
       "      <td>[woke, ., school, best, feel, ever]</td>\n",
       "      <td>[RB, VBD, RP, ., VBG, DT, NN, VBZ, DT, JJS, NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>[TheWDB.com - Very cool to hear old Walt inter...</td>\n",
       "      <td>[[(TheWDB, NNP), (., .), (com, NN), (-, :), (V...</td>\n",
       "      <td>[TheWDB, ., com, -, Very, cool, to, hear, old,...</td>\n",
       "      <td>[TheWDB, ., com, -, cool, hear, old, Walt, int...</td>\n",
       "      <td>[thewdb, ., com, -, cool, hear, old, walt, int...</td>\n",
       "      <td>[NNP, ., NN, :, RB, JJ, TO, VB, JJ, NNP, NN, ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>[Are you ready for your MoJo Makeover?, Ask me...</td>\n",
       "      <td>[[(Are, NNP), (you, PRP), (ready, JJ), (for, I...</td>\n",
       "      <td>[Are, you, ready, for, your, MoJo, Makeover, ?...</td>\n",
       "      <td>[ready, MoJo, Makeover, ?, Ask, details]</td>\n",
       "      <td>[readi, mojo, makeov, ?, ask, detail]</td>\n",
       "      <td>[NNP, PRP, JJ, IN, PRP$, NNP, NNP, ., VB, PRP,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>[Happy 38th Birthday to my boo of alll time!!!...</td>\n",
       "      <td>[[(Happy, JJ), (38th, CD), (Birthday, NN), (to...</td>\n",
       "      <td>[Happy, 38th, Birthday, to, my, boo, of, alll,...</td>\n",
       "      <td>[Happy, 38th, Birthday, boo, alll, time, !!!, ...</td>\n",
       "      <td>[happi, 38th, birthday, boo, alll, time, !!!, ...</td>\n",
       "      <td>[JJ, CD, NN, TO, PRP$, NN, IN, JJ, NN, NN, NNP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>happy #charitytuesday</td>\n",
       "      <td>[happy #charitytuesday]</td>\n",
       "      <td>[[(happy, JJ), (#charitytuesday, NN)]]</td>\n",
       "      <td>[happy, #charitytuesday]</td>\n",
       "      <td>[happy, #charitytuesday]</td>\n",
       "      <td>[happi, #charitytuesday]</td>\n",
       "      <td>[JJ, NN]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  \\\n",
       "0          - Awww, that's a bummer.  You shoulda got Da...   \n",
       "1        is upset that he can't update his Facebook by ...   \n",
       "2         I dived many times for the ball. Managed to s...   \n",
       "3          my whole body feels itchy and like its on fire    \n",
       "4         no, it's not behaving at all. i'm mad. why am...   \n",
       "...                                                    ...   \n",
       "1599995  Just woke up. Having no school is the best fee...   \n",
       "1599996  TheWDB.com - Very cool to hear old Walt interv...   \n",
       "1599997  Are you ready for your MoJo Makeover? Ask me f...   \n",
       "1599998  Happy 38th Birthday to my boo of alll time!!! ...   \n",
       "1599999                          happy #charitytuesday       \n",
       "\n",
       "                                           sentence_tokens  \\\n",
       "0        [  - Awww, that's a bummer., You shoulda got D...   \n",
       "1        [is upset that he can't update his Facebook by...   \n",
       "2        [ I dived many times for the ball., Managed to...   \n",
       "3         [my whole body feels itchy and like its on fire]   \n",
       "4        [ no, it's not behaving at all., i'm mad., why...   \n",
       "...                                                    ...   \n",
       "1599995  [Just woke up., Having no school is the best f...   \n",
       "1599996  [TheWDB.com - Very cool to hear old Walt inter...   \n",
       "1599997  [Are you ready for your MoJo Makeover?, Ask me...   \n",
       "1599998  [Happy 38th Birthday to my boo of alll time!!!...   \n",
       "1599999                            [happy #charitytuesday]   \n",
       "\n",
       "                                                  pos_tags  \\\n",
       "0        [[(-, :), (Awww, NN), (,, ,), (that, IN), (', ...   \n",
       "1        [[(is, VBZ), (upset, JJ), (that, IN), (he, PRP...   \n",
       "2        [[(I, PRP), (dived, VBD), (many, JJ), (times, ...   \n",
       "3        [[(my, PRP$), (whole, JJ), (body, NN), (feels,...   \n",
       "4        [[(no, DT), (,, ,), (it, PRP), (', ''), (s, VB...   \n",
       "...                                                    ...   \n",
       "1599995  [[(Just, RB), (woke, VBD), (up, RP), (., .)], ...   \n",
       "1599996  [[(TheWDB, NNP), (., .), (com, NN), (-, :), (V...   \n",
       "1599997  [[(Are, NNP), (you, PRP), (ready, JJ), (for, I...   \n",
       "1599998  [[(Happy, JJ), (38th, CD), (Birthday, NN), (to...   \n",
       "1599999             [[(happy, JJ), (#charitytuesday, NN)]]   \n",
       "\n",
       "                                               word_tokens  \\\n",
       "0        [-, Awww, ,, that, ', s, a, bummer, ., You, sh...   \n",
       "1        [is, upset, that, he, can, ', t, update, his, ...   \n",
       "2        [I, dived, many, times, for, the, ball, ., Man...   \n",
       "3        [my, whole, body, feels, itchy, and, like, its...   \n",
       "4        [no, ,, it, ', s, not, behaving, at, all, ., i...   \n",
       "...                                                    ...   \n",
       "1599995  [Just, woke, up, ., Having, no, school, is, th...   \n",
       "1599996  [TheWDB, ., com, -, Very, cool, to, hear, old,...   \n",
       "1599997  [Are, you, ready, for, your, MoJo, Makeover, ?...   \n",
       "1599998  [Happy, 38th, Birthday, to, my, boo, of, alll,...   \n",
       "1599999                           [happy, #charitytuesday]   \n",
       "\n",
       "                                 word_tokens_no_stop_words  \\\n",
       "0        [-, Awww, ,, ', bummer, ., shoulda, got, David...   \n",
       "1        [upset, ', update, Facebook, texting, ..., mig...   \n",
       "2        [dived, many, times, ball, ., Managed, save, 5...   \n",
       "3                  [whole, body, feels, itchy, like, fire]   \n",
       "4             [,, ', behaving, ., ', mad, ., ?, ', see, .]   \n",
       "...                                                    ...   \n",
       "1599995             [woke, ., school, best, feeling, ever]   \n",
       "1599996  [TheWDB, ., com, -, cool, hear, old, Walt, int...   \n",
       "1599997           [ready, MoJo, Makeover, ?, Ask, details]   \n",
       "1599998  [Happy, 38th, Birthday, boo, alll, time, !!!, ...   \n",
       "1599999                           [happy, #charitytuesday]   \n",
       "\n",
       "                               word_tokens_no_stop_stemmed  \\\n",
       "0        [-, awww, ,, ', bummer, ., shoulda, got, david...   \n",
       "1        [upset, ', updat, facebook, text, ..., might, ...   \n",
       "2        [dive, mani, time, ball, ., manag, save, 50, %...   \n",
       "3                   [whole, bodi, feel, itchi, like, fire]   \n",
       "4                [,, ', behav, ., ', mad, ., ?, ', see, .]   \n",
       "...                                                    ...   \n",
       "1599995                [woke, ., school, best, feel, ever]   \n",
       "1599996  [thewdb, ., com, -, cool, hear, old, walt, int...   \n",
       "1599997              [readi, mojo, makeov, ?, ask, detail]   \n",
       "1599998  [happi, 38th, birthday, boo, alll, time, !!!, ...   \n",
       "1599999                           [happi, #charitytuesday]   \n",
       "\n",
       "                          word_tokens_no_stop_adjusted_pos  \n",
       "0        [:, NN, ,, IN, '', VB, DT, NN, ., PRP, VBP, VB...  \n",
       "1        [VBZ, JJ, IN, PRP, MD, '', VB, VB, PRP$, NNP, ...  \n",
       "2        [PRP, VBD, JJ, NNS, IN, DT, NN, ., VBN, TO, VB...  \n",
       "3          [PRP$, JJ, NN, NNS, VBP, CC, VBP, PRP$, IN, NN]  \n",
       "4        [DT, ,, PRP, '', VBZ, RB, VBG, IN, DT, ., NN, ...  \n",
       "...                                                    ...  \n",
       "1599995  [RB, VBD, RP, ., VBG, DT, NN, VBZ, DT, JJS, NN...  \n",
       "1599996  [NNP, ., NN, :, RB, JJ, TO, VB, JJ, NNP, NN, ....  \n",
       "1599997  [NNP, PRP, JJ, IN, PRP$, NNP, NNP, ., VB, PRP,...  \n",
       "1599998  [JJ, CD, NN, TO, PRP$, NN, IN, JJ, NN, NN, NNP...  \n",
       "1599999                                           [JJ, NN]  \n",
       "\n",
       "[1600000 rows x 7 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WordNet POS tags are: NOUN = 'n', ADJ = 's', VERB = 'v', ADV = 'r', ADJ_SAT = 'a'\n",
    "# Descriptions (c) https://web.stanford.edu/~jurafsky/slp3/10.pdf\n",
    "tag_map = {\n",
    "        'CC':None, # coordin. conjunction (and, but, or)  \n",
    "        'CD':wn.NOUN, # cardinal number (one, two)             \n",
    "        'DT':None, # determiner (a, the)                    \n",
    "        'EX':wn.ADV, # existential ‘there’ (there)           \n",
    "        'FW':None, # foreign word (mea culpa)             \n",
    "        'IN':wn.ADV, # preposition/sub-conj (of, in, by)   \n",
    "        'JJ':[wn.ADJ, wn.ADJ_SAT], # adjective (yellow)                  \n",
    "        'JJR':[wn.ADJ, wn.ADJ_SAT], # adj., comparative (bigger)          \n",
    "        'JJS':[wn.ADJ, wn.ADJ_SAT], # adj., superlative (wildest)           \n",
    "        'LS':None, # list item marker (1, 2, One)          \n",
    "        'MD':None, # modal (can, should)                    \n",
    "        'NN':wn.NOUN, # noun, sing. or mass (llama)          \n",
    "        'NNS':wn.NOUN, # noun, plural (llamas)                  \n",
    "        'NNP':wn.NOUN, # proper noun, sing. (IBM)              \n",
    "        'NNPS':wn.NOUN, # proper noun, plural (Carolinas)\n",
    "        'PDT':[wn.ADJ, wn.ADJ_SAT], # predeterminer (all, both)            \n",
    "        'POS':None, # possessive ending (’s )               \n",
    "        'PRP':None, # personal pronoun (I, you, he)     \n",
    "        'PRP$':None, # possessive pronoun (your, one’s)    \n",
    "        'RB':wn.ADV, # adverb (quickly, never)            \n",
    "        'RBR':wn.ADV, # adverb, comparative (faster)        \n",
    "        'RBS':wn.ADV, # adverb, superlative (fastest)     \n",
    "        'RP':[wn.ADJ, wn.ADJ_SAT], # particle (up, off)\n",
    "        'SYM':None, # symbol (+,%, &)\n",
    "        'TO':None, # “to” (to)\n",
    "        'UH':None, # interjection (ah, oops)\n",
    "        'VB':wn.VERB, # verb base form (eat)\n",
    "        'VBD':wn.VERB, # verb past tense (ate)\n",
    "        'VBG':wn.VERB, # verb gerund (eating)\n",
    "        'VBN':wn.VERB, # verb past participle (eaten)\n",
    "        'VBP':wn.VERB, # verb non-3sg pres (eat)\n",
    "        'VBZ':wn.VERB, # verb 3sg pres (eats)\n",
    "        'WDT':None, # wh-determiner (which, that)\n",
    "        'WP':None, # wh-pronoun (what, who)\n",
    "        'WP$':None, # possessive (wh- whose)\n",
    "        'WRB':None, # wh-adverb (how, where)\n",
    "        '$':None, #  dollar sign ($)\n",
    "        '#':None, # pound sign (#)\n",
    "        '“':None, # left quote (‘ or “)\n",
    "        '”':None, # right quote (’ or ”)\n",
    "        \"''\":None,\n",
    "        '(':None, # left parenthesis ([, (, {, <)\n",
    "        ')':None, # right parenthesis (], ), }, >)\n",
    "        ',':None, # comma (,)\n",
    "        '.':None, # sentence-final punc (. ! ?)\n",
    "        ':':None # mid-sentence punc (: ; ... – -)\n",
    "    }\n",
    "processed_df['word_tokens_no_stop_adjusted_pos'] = processed_df[['pos_tags', 'word_tokens_no_stop_words']].apply(\n",
    "    lambda x: [w[1] for s in x['pos_tags'] for w in s], axis=1)\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35956006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing words in Tweet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# processed_df['word_tokens_no_stop_lemmatized'] = processed_df['word_tokens_no_stop_words'].apply(lambda x: [lemmatizer.lemmatize(w) for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaa034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize(\"cannot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a8fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc251d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.iloc[4]['pos_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210a3b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f9d5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e7498be",
   "metadata": {},
   "source": [
    "# GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac33671f",
   "metadata": {},
   "source": [
    "### Download GloVe Twitter Pre-Trained Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc825e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('http://nlp.stanford.edu/data/glove.twitter.27B.zip', stream=True)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall(\"GloVe.Twitter.27B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99fcaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
