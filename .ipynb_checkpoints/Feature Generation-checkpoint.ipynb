{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e25f7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\techn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\techn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\techn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\techn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\techn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests, zipfile, io, re, nltk\n",
    "from datetime import datetime, timedelta\n",
    "import tensorflow as tf\n",
    "from keras import models, layers\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, TweetTokenizer, wordpunct_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6badafe",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371865ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin-1', header=None,\n",
    "                         names=['polarity', 'id', 'date', 'query', 'user', 'tweet'])\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d16e3da",
   "metadata": {},
   "source": [
    "### Removing Unnecessary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc93547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df.drop(columns=['id', 'query', 'polarity', 'user', 'date'])\n",
    "# df['datetime'] = raw_df['date'].apply(lambda x: pd.to_datetime(x.replace('PDT ', '')))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffbb341",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = raw_df['polarity']\n",
    "print(f\"Unique Elements of y: {pd.unique(y)}\")\n",
    "# Change y from [0, 4] to [0, 1]\n",
    "y = y.apply(lambda x: 1 if x==4 else 0)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b36aeb0",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c98a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = df.copy(deep=True)\n",
    "tokenizer = RegexpTokenizer(r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)|\\w+|[^\\w\\s]+\")\n",
    "\n",
    "\n",
    "# Remove URLs and User Mentions. All Twitter handles must be within 4 to 15 characters\n",
    "processed_df['tweet'] = processed_df['tweet'].apply(lambda x: re.sub(r\"http\\S+|@\\w{4,15}|#\", \"\", x))\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3c2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize Tweets into Sentences\n",
    "processed_df['sentence_tokens'] = processed_df['tweet'].apply(lambda x: sent_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a12bbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract Part-Of-Speech Tags\n",
    "processed_df['pos_tags'] = processed_df['sentence_tokens'].apply(lambda x: [nltk.pos_tag(tokenizer.tokenize(sent)) for sent in x])\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d02fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern = regex.compile(r\"(.)/\\1{2,}\")\n",
    "# pattern.sub(r\"\\1\\1\\1\", text)\n",
    "# Tokenize Tweets into Words\n",
    "processed_df['word_tokens'] = processed_df['tweet'].apply(lambda x: tokenizer.tokenize(x))\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec49a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate stop words\n",
    "print(\"Stop Words: \", stopwords.words('english'))\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Remove stop words from tokenized tweets\n",
    "processed_df['word_tokens_no_stop_words'] = processed_df['word_tokens'].apply(lambda x: [w for w in x if not w.lower() in stop_words])\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f76fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Source: https://github.com/nltk/nltk/blob/develop/nltk/stem/wordnet.py\n",
    "def penn2morphy(penntag) -> str:\n",
    "    \"\"\"\n",
    "    Converts tags from Penn format (input: single string) to Morphy.\n",
    "    \"\"\"\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a', 'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "processed_df['pos_tags_adjusted_no_stop_words'] = processed_df['pos_tags'].apply(\n",
    "    lambda x: [(w[0], penn2morphy(w[1])) for s in x for w in s if not w[0].lower() in stop_words])\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c023a3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Stemming words in Tweet\n",
    "ps = PorterStemmer()\n",
    "processed_df['word_tokens_no_stop_stemmed'] = processed_df['word_tokens_no_stop_words'].apply(lambda x: [ps.stem(w) for w in x if not w == ''])\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35956006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing words in Tweet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "processed_df['word_tokens_no_stop_lemmatized'] = processed_df['pos_tags_adjusted_no_stop_words'].apply(lambda x: [lemmatizer.lemmatize(word=w[0].lower(), pos=w[1]) if w[1] != None else w[0].lower() for w in x])\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308ba15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "processed_df['tweet_str_no_stop_stemmed'] = processed_df['word_tokens_no_stop_stemmed'].apply(lambda x: ' '.join(x).translate(str.maketrans('', '', string.punctuation)))\n",
    "processed_df['tweet_str_no_stop_lemmatized'] = processed_df['word_tokens_no_stop_lemmatized'].apply(lambda x: ' '.join(x).translate(str.maketrans('', '', string.punctuation)))\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ffc192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle processed_df\n",
    "y.to_pickle(\"y.pickle\")\n",
    "processed_df.to_pickle(\"processed_df.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53bd3ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentence_tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>word_tokens_no_stop_words</th>\n",
       "      <th>pos_tags_adjusted_no_stop_words</th>\n",
       "      <th>word_tokens_no_stop_stemmed</th>\n",
       "      <th>word_tokens_no_stop_lemmatized</th>\n",
       "      <th>tweet_str_no_stop_stemmed</th>\n",
       "      <th>tweet_str_no_stop_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- Awww, that's a bummer.  You shoulda got Da...</td>\n",
       "      <td>[  - Awww, that's a bummer., You shoulda got D...</td>\n",
       "      <td>[[(-, :), (Awww, NN), (,, ,), (that, IN), (', ...</td>\n",
       "      <td>[-, Awww, ,, that, ', s, a, bummer, ., You, sh...</td>\n",
       "      <td>[-, Awww, ,, ', bummer, ., shoulda, got, David...</td>\n",
       "      <td>[(-, None), (Awww, n), (,, None), (', None), (...</td>\n",
       "      <td>[-, awww, ,, ', bummer, ., shoulda, got, david...</td>\n",
       "      <td>[-, awww, ,, ', bummer, ., shoulda, get, david...</td>\n",
       "      <td>awww   bummer  shoulda got david carr third d...</td>\n",
       "      <td>awww   bummer  shoulda get david carr third d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>[is upset that he can't update his Facebook by...</td>\n",
       "      <td>[[(is, VBZ), (upset, JJ), (that, IN), (he, PRP...</td>\n",
       "      <td>[is, upset, that, he, can, ', t, update, his, ...</td>\n",
       "      <td>[upset, ', update, Facebook, texting, ..., mig...</td>\n",
       "      <td>[(upset, a), (', None), (update, v), (Facebook...</td>\n",
       "      <td>[upset, ', updat, facebook, text, ..., might, ...</td>\n",
       "      <td>[upset, ', update, facebook, texting, ..., mig...</td>\n",
       "      <td>upset  updat facebook text  might cri result s...</td>\n",
       "      <td>upset  update facebook texting  might cry resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I dived many times for the ball. Managed to s...</td>\n",
       "      <td>[ I dived many times for the ball., Managed to...</td>\n",
       "      <td>[[(I, PRP), (dived, VBD), (many, JJ), (times, ...</td>\n",
       "      <td>[I, dived, many, times, for, the, ball, ., Man...</td>\n",
       "      <td>[dived, many, times, ball, ., Managed, save, 5...</td>\n",
       "      <td>[(dived, v), (many, a), (times, n), (ball, n),...</td>\n",
       "      <td>[dive, mani, time, ball, ., manag, save, 50, %...</td>\n",
       "      <td>[dive, many, time, ball, ., manage, save, 50, ...</td>\n",
       "      <td>dive mani time ball  manag save 50  rest go bound</td>\n",
       "      <td>dive many time ball  manage save 50  rest go b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my whole body feels itchy and like its on fire]</td>\n",
       "      <td>[[(my, PRP$), (whole, JJ), (body, NN), (feels,...</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
       "      <td>[(whole, a), (body, n), (feels, n), (itchy, v)...</td>\n",
       "      <td>[whole, bodi, feel, itchi, like, fire]</td>\n",
       "      <td>[whole, body, feel, itchy, like, fire]</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am...</td>\n",
       "      <td>[ no, it's not behaving at all., i'm mad., why...</td>\n",
       "      <td>[[(no, DT), (,, ,), (it, PRP), (', ''), (s, VB...</td>\n",
       "      <td>[no, ,, it, ', s, not, behaving, at, all, ., i...</td>\n",
       "      <td>[,, ', behaving, ., ', mad, ., ?, ', see, .]</td>\n",
       "      <td>[(,, None), (', None), (behaving, v), (., None...</td>\n",
       "      <td>[,, ', behav, ., ', mad, ., ?, ', see, .]</td>\n",
       "      <td>[,, ', behave, ., ', mad, ., ?, ', see, .]</td>\n",
       "      <td>behav   mad    see</td>\n",
       "      <td>behave   mad    see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>[Just woke up., Having no school is the best f...</td>\n",
       "      <td>[[(Just, RB), (woke, VBD), (up, RP), (., .)], ...</td>\n",
       "      <td>[Just, woke, up, ., Having, no, school, is, th...</td>\n",
       "      <td>[woke, ., school, best, feeling, ever]</td>\n",
       "      <td>[(woke, v), (., None), (school, n), (best, a),...</td>\n",
       "      <td>[woke, ., school, best, feel, ever]</td>\n",
       "      <td>[wake, ., school, best, feeling, ever]</td>\n",
       "      <td>woke  school best feel ever</td>\n",
       "      <td>wake  school best feeling ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>[TheWDB.com - Very cool to hear old Walt inter...</td>\n",
       "      <td>[[(TheWDB, NNP), (., .), (com, NN), (-, :), (V...</td>\n",
       "      <td>[TheWDB, ., com, -, Very, cool, to, hear, old,...</td>\n",
       "      <td>[TheWDB, ., com, -, cool, hear, old, Walt, int...</td>\n",
       "      <td>[(TheWDB, n), (., None), (com, n), (-, None), ...</td>\n",
       "      <td>[thewdb, ., com, -, cool, hear, old, walt, int...</td>\n",
       "      <td>[thewdb, ., com, -, cool, hear, old, walt, int...</td>\n",
       "      <td>thewdb  com  cool hear old walt interview  â «</td>\n",
       "      <td>thewdb  com  cool hear old walt interview  â «</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>[Are you ready for your MoJo Makeover?, Ask me...</td>\n",
       "      <td>[[(Are, NNP), (you, PRP), (ready, JJ), (for, I...</td>\n",
       "      <td>[Are, you, ready, for, your, MoJo, Makeover, ?...</td>\n",
       "      <td>[ready, MoJo, Makeover, ?, Ask, details]</td>\n",
       "      <td>[(ready, a), (MoJo, n), (Makeover, n), (?, Non...</td>\n",
       "      <td>[readi, mojo, makeov, ?, ask, detail]</td>\n",
       "      <td>[ready, mojo, makeover, ?, ask, detail]</td>\n",
       "      <td>readi mojo makeov  ask detail</td>\n",
       "      <td>ready mojo makeover  ask detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>[Happy 38th Birthday to my boo of alll time!!!...</td>\n",
       "      <td>[[(Happy, JJ), (38th, CD), (Birthday, NN), (to...</td>\n",
       "      <td>[Happy, 38th, Birthday, to, my, boo, of, alll,...</td>\n",
       "      <td>[Happy, 38th, Birthday, boo, alll, time, !!!, ...</td>\n",
       "      <td>[(Happy, a), (38th, None), (Birthday, n), (boo...</td>\n",
       "      <td>[happi, 38th, birthday, boo, alll, time, !!!, ...</td>\n",
       "      <td>[happy, 38th, birthday, boo, alll, time, !!!, ...</td>\n",
       "      <td>happi 38th birthday boo alll time  tupac amaru...</td>\n",
       "      <td>happy 38th birthday boo alll time  tupac amaru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>happy charitytuesday</td>\n",
       "      <td>[happy charitytuesday]</td>\n",
       "      <td>[[(happy, JJ), (charitytuesday, NN)]]</td>\n",
       "      <td>[happy, charitytuesday]</td>\n",
       "      <td>[happy, charitytuesday]</td>\n",
       "      <td>[(happy, a), (charitytuesday, n)]</td>\n",
       "      <td>[happi, charitytuesday]</td>\n",
       "      <td>[happy, charitytuesday]</td>\n",
       "      <td>happi charitytuesday</td>\n",
       "      <td>happy charitytuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     tweet  \\\n",
       "0          - Awww, that's a bummer.  You shoulda got Da...   \n",
       "1        is upset that he can't update his Facebook by ...   \n",
       "2         I dived many times for the ball. Managed to s...   \n",
       "3          my whole body feels itchy and like its on fire    \n",
       "4         no, it's not behaving at all. i'm mad. why am...   \n",
       "...                                                    ...   \n",
       "1599995  Just woke up. Having no school is the best fee...   \n",
       "1599996  TheWDB.com - Very cool to hear old Walt interv...   \n",
       "1599997  Are you ready for your MoJo Makeover? Ask me f...   \n",
       "1599998  Happy 38th Birthday to my boo of alll time!!! ...   \n",
       "1599999                           happy charitytuesday       \n",
       "\n",
       "                                           sentence_tokens  \\\n",
       "0        [  - Awww, that's a bummer., You shoulda got D...   \n",
       "1        [is upset that he can't update his Facebook by...   \n",
       "2        [ I dived many times for the ball., Managed to...   \n",
       "3         [my whole body feels itchy and like its on fire]   \n",
       "4        [ no, it's not behaving at all., i'm mad., why...   \n",
       "...                                                    ...   \n",
       "1599995  [Just woke up., Having no school is the best f...   \n",
       "1599996  [TheWDB.com - Very cool to hear old Walt inter...   \n",
       "1599997  [Are you ready for your MoJo Makeover?, Ask me...   \n",
       "1599998  [Happy 38th Birthday to my boo of alll time!!!...   \n",
       "1599999                             [happy charitytuesday]   \n",
       "\n",
       "                                                  pos_tags  \\\n",
       "0        [[(-, :), (Awww, NN), (,, ,), (that, IN), (', ...   \n",
       "1        [[(is, VBZ), (upset, JJ), (that, IN), (he, PRP...   \n",
       "2        [[(I, PRP), (dived, VBD), (many, JJ), (times, ...   \n",
       "3        [[(my, PRP$), (whole, JJ), (body, NN), (feels,...   \n",
       "4        [[(no, DT), (,, ,), (it, PRP), (', ''), (s, VB...   \n",
       "...                                                    ...   \n",
       "1599995  [[(Just, RB), (woke, VBD), (up, RP), (., .)], ...   \n",
       "1599996  [[(TheWDB, NNP), (., .), (com, NN), (-, :), (V...   \n",
       "1599997  [[(Are, NNP), (you, PRP), (ready, JJ), (for, I...   \n",
       "1599998  [[(Happy, JJ), (38th, CD), (Birthday, NN), (to...   \n",
       "1599999              [[(happy, JJ), (charitytuesday, NN)]]   \n",
       "\n",
       "                                               word_tokens  \\\n",
       "0        [-, Awww, ,, that, ', s, a, bummer, ., You, sh...   \n",
       "1        [is, upset, that, he, can, ', t, update, his, ...   \n",
       "2        [I, dived, many, times, for, the, ball, ., Man...   \n",
       "3        [my, whole, body, feels, itchy, and, like, its...   \n",
       "4        [no, ,, it, ', s, not, behaving, at, all, ., i...   \n",
       "...                                                    ...   \n",
       "1599995  [Just, woke, up, ., Having, no, school, is, th...   \n",
       "1599996  [TheWDB, ., com, -, Very, cool, to, hear, old,...   \n",
       "1599997  [Are, you, ready, for, your, MoJo, Makeover, ?...   \n",
       "1599998  [Happy, 38th, Birthday, to, my, boo, of, alll,...   \n",
       "1599999                            [happy, charitytuesday]   \n",
       "\n",
       "                                 word_tokens_no_stop_words  \\\n",
       "0        [-, Awww, ,, ', bummer, ., shoulda, got, David...   \n",
       "1        [upset, ', update, Facebook, texting, ..., mig...   \n",
       "2        [dived, many, times, ball, ., Managed, save, 5...   \n",
       "3                  [whole, body, feels, itchy, like, fire]   \n",
       "4             [,, ', behaving, ., ', mad, ., ?, ', see, .]   \n",
       "...                                                    ...   \n",
       "1599995             [woke, ., school, best, feeling, ever]   \n",
       "1599996  [TheWDB, ., com, -, cool, hear, old, Walt, int...   \n",
       "1599997           [ready, MoJo, Makeover, ?, Ask, details]   \n",
       "1599998  [Happy, 38th, Birthday, boo, alll, time, !!!, ...   \n",
       "1599999                            [happy, charitytuesday]   \n",
       "\n",
       "                           pos_tags_adjusted_no_stop_words  \\\n",
       "0        [(-, None), (Awww, n), (,, None), (', None), (...   \n",
       "1        [(upset, a), (', None), (update, v), (Facebook...   \n",
       "2        [(dived, v), (many, a), (times, n), (ball, n),...   \n",
       "3        [(whole, a), (body, n), (feels, n), (itchy, v)...   \n",
       "4        [(,, None), (', None), (behaving, v), (., None...   \n",
       "...                                                    ...   \n",
       "1599995  [(woke, v), (., None), (school, n), (best, a),...   \n",
       "1599996  [(TheWDB, n), (., None), (com, n), (-, None), ...   \n",
       "1599997  [(ready, a), (MoJo, n), (Makeover, n), (?, Non...   \n",
       "1599998  [(Happy, a), (38th, None), (Birthday, n), (boo...   \n",
       "1599999                  [(happy, a), (charitytuesday, n)]   \n",
       "\n",
       "                               word_tokens_no_stop_stemmed  \\\n",
       "0        [-, awww, ,, ', bummer, ., shoulda, got, david...   \n",
       "1        [upset, ', updat, facebook, text, ..., might, ...   \n",
       "2        [dive, mani, time, ball, ., manag, save, 50, %...   \n",
       "3                   [whole, bodi, feel, itchi, like, fire]   \n",
       "4                [,, ', behav, ., ', mad, ., ?, ', see, .]   \n",
       "...                                                    ...   \n",
       "1599995                [woke, ., school, best, feel, ever]   \n",
       "1599996  [thewdb, ., com, -, cool, hear, old, walt, int...   \n",
       "1599997              [readi, mojo, makeov, ?, ask, detail]   \n",
       "1599998  [happi, 38th, birthday, boo, alll, time, !!!, ...   \n",
       "1599999                            [happi, charitytuesday]   \n",
       "\n",
       "                            word_tokens_no_stop_lemmatized  \\\n",
       "0        [-, awww, ,, ', bummer, ., shoulda, get, david...   \n",
       "1        [upset, ', update, facebook, texting, ..., mig...   \n",
       "2        [dive, many, time, ball, ., manage, save, 50, ...   \n",
       "3                   [whole, body, feel, itchy, like, fire]   \n",
       "4               [,, ', behave, ., ', mad, ., ?, ', see, .]   \n",
       "...                                                    ...   \n",
       "1599995             [wake, ., school, best, feeling, ever]   \n",
       "1599996  [thewdb, ., com, -, cool, hear, old, walt, int...   \n",
       "1599997            [ready, mojo, makeover, ?, ask, detail]   \n",
       "1599998  [happy, 38th, birthday, boo, alll, time, !!!, ...   \n",
       "1599999                            [happy, charitytuesday]   \n",
       "\n",
       "                                 tweet_str_no_stop_stemmed  \\\n",
       "0         awww   bummer  shoulda got david carr third d...   \n",
       "1        upset  updat facebook text  might cri result s...   \n",
       "2        dive mani time ball  manag save 50  rest go bound   \n",
       "3                          whole bodi feel itchi like fire   \n",
       "4                                      behav   mad    see    \n",
       "...                                                    ...   \n",
       "1599995                        woke  school best feel ever   \n",
       "1599996    thewdb  com  cool hear old walt interview  â «   \n",
       "1599997                      readi mojo makeov  ask detail   \n",
       "1599998  happi 38th birthday boo alll time  tupac amaru...   \n",
       "1599999                               happi charitytuesday   \n",
       "\n",
       "                              tweet_str_no_stop_lemmatized  \n",
       "0         awww   bummer  shoulda get david carr third d...  \n",
       "1        upset  update facebook texting  might cry resu...  \n",
       "2        dive many time ball  manage save 50  rest go b...  \n",
       "3                          whole body feel itchy like fire  \n",
       "4                                     behave   mad    see   \n",
       "...                                                    ...  \n",
       "1599995                     wake  school best feeling ever  \n",
       "1599996    thewdb  com  cool hear old walt interview  â «  \n",
       "1599997                    ready mojo makeover  ask detail  \n",
       "1599998  happy 38th birthday boo alll time  tupac amaru...  \n",
       "1599999                               happy charitytuesday  \n",
       "\n",
       "[1600000 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read processed_df from pickle file\n",
    "processed_df = pd.read_pickle(\"processed_df.pickle\")\n",
    "y = pd.read_pickle(\"y.pickle\")\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7498be",
   "metadata": {},
   "source": [
    "# GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac33671f",
   "metadata": {},
   "source": [
    "### Download GloVe Twitter Pre-Trained Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc825e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and Extract GloVe Twitter Vectors\n",
    "r = requests.get('http://nlp.stanford.edu/data/glove.twitter.27B.zip', stream=True)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall(\"GloVe.Twitter.27B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd30da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "# Simple Kfold\n",
    "def kfold(network, neg_tweets, pos_tweets, batch_size):\n",
    "    kf = KFold(n_splits=5)\n",
    "    n = 0\n",
    "    fold_times = []\n",
    "    histories = []\n",
    "    if len(neg_tweets) > len(pos_tweets):\n",
    "        tweets = pos_tweets \n",
    "    else: tweets = neg_tweets\n",
    "    for train_idx, test_idx in kf.split(tweets):\n",
    "        start = datetime.now()\n",
    "        print(f\"Fold {n}\")\n",
    "        n+=1\n",
    "        print(f\"Test Index Start:{test_idx[0]}\")\n",
    "        print(f\"Test Set Size:{len(test_idx)}\")\n",
    "        train_tweets = np.append(neg_tweets[train_idx], pos_tweets[train_idx], axis=0)\n",
    "        train_labels = np.append(np.full(len(train_idx), 0), np.full(len(train_idx), 1))\n",
    "\n",
    "        test_tweets = np.append(neg_tweets[test_idx], pos_tweets[test_idx], axis=0)\n",
    "        test_labels = np.append(np.full(len(test_idx), 0), np.full(len(test_idx), 1))\n",
    "        validation_data = (test_tweets, test_labels)\n",
    "        \n",
    "        history = network.fit(train_tweets, train_labels, batch_size=batch_size, validation_data=validation_data, \n",
    "                              epochs=20, verbose=0, use_multiprocessing=True)\n",
    "        histories.append(history)\n",
    "        summarize_diagnostics(history=history) \n",
    "#         train_loss, train_acc = network.evaluate(train_tweets, train_labels, verbose=1)\n",
    "#         test_loss, test_acc = network.evaluate(test_tweets, test_labels, verbose=1)\n",
    "#         print(f\"Train Loss: {train_loss}; Train Accuracy: {train_acc}\")\n",
    "#         print(f\"Test Loss: {test_loss}; Test Accuracy: {test_acc}\")\n",
    "        fold_time = datetime.now()-start\n",
    "        fold_times.append(fold_time.total_seconds())\n",
    "        print(\"fold time: \", fold_time)\n",
    "    summarize_diagnostics(histories=histories)\n",
    "    print(timedelta(seconds=np.average(fold_times)))\n",
    "\n",
    "# Plots results to graph\n",
    "import matplotlib.pyplot as plt\n",
    "def summarize_diagnostics(history=None, histories=None):\n",
    "    # plot loss\n",
    "    plt.subplot(211)\n",
    "    plt.tight_layout()\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    if history:\n",
    "        plt.plot(history.history['loss'], color='blue', label='train')\n",
    "        plt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    else:\n",
    "        plt.plot(np.mean([history.history['loss'] for history in histories], axis=0), color='blue', label='train')\n",
    "        plt.plot(np.mean([history.history['val_loss'] for history in histories], axis=0), color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    plt.subplot(212)\n",
    "    plt.title('Classification Accuracy')\n",
    "    if history:\n",
    "        plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "        plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    else:\n",
    "        plt.plot(np.mean([history.history['accuracy'] for history in histories], axis=0), color='blue', label='train')\n",
    "        plt.plot(np.mean([history.history['val_accuracy'] for history in histories], axis=0), color='orange', label='test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f63f194",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                32064     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,665\n",
      "Trainable params: 73,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, input_dim=500, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(8, activation='relu'),\n",
    "#     tf.keras.layers.Dense(16, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30659b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed06c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 200000\n",
      "Fold 0\n",
      "Test Index Start:0\n",
      "Test Set Size:40000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold time:  0:01:20.973552\n",
      "Fold 1\n",
      "Test Index Start:40000\n",
      "Test Set Size:40000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m pos_tweets_stem \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([X[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y)) \u001b[38;5;28;01mif\u001b[39;00m y[i]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(X[i])])[:\u001b[38;5;241m200000\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(neg_tweets_stem), \u001b[38;5;28mlen\u001b[39m(pos_tweets_stem))\n\u001b[1;32m----> 7\u001b[0m \u001b[43mkfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_tweets_stem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_tweets_stem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mkfold\u001b[1;34m(network, neg_tweets, pos_tweets, batch_size)\u001b[0m\n\u001b[0;32m     21\u001b[0m test_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mfull(\u001b[38;5;28mlen\u001b[39m(test_idx), \u001b[38;5;241m0\u001b[39m), np\u001b[38;5;241m.\u001b[39mfull(\u001b[38;5;28mlen\u001b[39m(test_idx), \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     22\u001b[0m validation_data \u001b[38;5;241m=\u001b[39m (test_tweets, test_labels)\n\u001b[1;32m---> 24\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_tweets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m histories\u001b[38;5;241m.\u001b[39mappend(history)\n\u001b[0;32m     27\u001b[0m summarize_diagnostics(history\u001b[38;5;241m=\u001b[39mhistory) \n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create bag of words featureset for stemmed \n",
    "cv=CountVectorizer(max_features=500)\n",
    "X=cv.fit_transform(processed_df['word_tokens_no_stop_stemmed'].apply(' '.join)).toarray()\n",
    "neg_tweets_stem = np.array([X[i] for i in range(len(y)) if y[i]==0 and any(X[i])])[:200000]\n",
    "pos_tweets_stem = np.array([X[i] for i in range(len(y)) if y[i]==1 and any(X[i])])[:200000]\n",
    "print(len(neg_tweets_stem), len(pos_tweets_stem))\n",
    "kfold(model, neg_tweets_stem, pos_tweets_stem, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58da8800",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create bag of words featureset for stemmed \n",
    "cv=CountVectorizer(max_features=1000)\n",
    "X=cv.fit_transform(processed_df['word_tokens_no_stop_stemmed'].apply(' '.join)).toarray()\n",
    "neg_tweets_stem = np.array([X[i] for i in range(len(y)) if y[i]==0])[:200000]\n",
    "pos_tweets_stem = np.array([X[i] for i in range(len(y)) if y[i]==1])[:200000]\n",
    "print(len(neg_tweets_stem), len(pos_tweets_stem))\n",
    "kfold(model, neg_tweets_stem, pos_tweets_stem, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac4ed3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv=CountVectorizer(max_features=1000)\n",
    "X=cv.fit_transform().toarray()\n",
    "neg_tweets_lemm = np.array([X[i] for i in range(len(y)) if y[i]==0])[:200000]\n",
    "pos_tweets_lemm = np.array([X[i] for i in range(len(y)) if y[i]==1])[:200000]\n",
    "print(len(neg_tweets_lemm), len(pos_tweets_lemm))\n",
    "kfold(model, neg_tweets_lemm, pos_tweets_lemm, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f5a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 500, 100)          500       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 250, 100)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               6400256   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,401,013\n",
      "Trainable params: 6,401,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "200000 200000\n",
      "Fold 0\n",
      "Test Index Start:0\n",
      "Test Set Size:40000\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(100, 4, padding=\"same\", activation=\"relu\", input_shape=(500, 1)),\n",
    "    tf.keras.layers.MaxPooling1D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='softmax'),\n",
    "\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "     loss='binary_crossentropy',\n",
    "     optimizer='adam',\n",
    "     metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "cv=CountVectorizer(max_features=500)\n",
    "X=cv.fit_transform(processed_df['word_tokens_no_stop_lemmatized'].apply(' '.join)).toarray()\n",
    "neg_tweets_lemm = np.array([X[i] for i in range(len(y)) if y[i]==0])[:200000]\n",
    "pos_tweets_lemm = np.array([X[i] for i in range(len(y)) if y[i]==1])[:200000]\n",
    "print(len(neg_tweets_lemm), len(pos_tweets_lemm))\n",
    "kfold(model, neg_tweets_lemm, pos_tweets_lemm, 64)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05167639",
   "metadata": {},
   "source": [
    "max_words = 5000\n",
    "k_tokenizer = Tokenizer(num_words=max_words)\n",
    "k_tokenizer.fit_on_texts(processed_df['word_tokens_no_stop_stemmed'])\n",
    "X = processed_df['word_tokens_no_stop_stemmed'].apply(k_tokenizer.texts_to_sequences)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1846e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
